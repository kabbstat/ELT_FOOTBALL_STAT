# âš½ Football ELT Pipeline - Production Grade

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Airflow](https://img.shields.io/badge/Airflow-2.7+-red.svg)
![DBT](https://img.shields.io/badge/DBT-1.6+-orange.svg)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)

Un pipeline ELT complet et de niveau production pour l'extraction, transformation et visualisation de statistiques de football (Premier League, La Liga, Ligue 1).

## ğŸ“‹ Table des MatiÃ¨res

- [Architecture](#architecture)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Stack Technique](#stack-technique)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Structure du Projet](#structure-du-projet)
- [QualitÃ© des DonnÃ©es](#qualitÃ©-des-donnÃ©es)
- [Dashboard](#dashboard)
- [Bonnes Pratiques](#bonnes-pratiques)

## ğŸ—ï¸ Architecture

Ce projet suit une **architecture mÃ©daillÃ©e** (Bronze/Silver/Gold) avec les bonnes pratiques de data engineering :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Football API  â”‚
â”‚  (Data Source)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    [EXTRACT]
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bronze Layer   â”‚ â† Raw data (JSON â†’ Parquet â†’ PostgreSQL)
â”‚   (PostgreSQL)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    [TRANSFORM]
      (DBT)
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚Silverâ”‚  â”‚ Gold â”‚ â† Business logic & aggregations
â””â”€â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜
    â”‚        â”‚
    â–¼        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dashboard     â”‚ â† Streamlit visualization
â”‚  (Streamlit)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Couches de DonnÃ©es

- **Bronze** : DonnÃ©es brutes extraites de l'API
- **Silver** : DonnÃ©es nettoyÃ©es et standardisÃ©es (`stg_matches`, `stg_teams`)
- **Gold** : AgrÃ©gations et mÃ©triques business (`fact_matches`, `dim_teams`, `agg_team_performance`, `agg_competition_stats`)

## âœ¨ FonctionnalitÃ©s

### Pipeline ELT

- âœ… **Extraction automatisÃ©e** depuis Football-Data.org API
- âœ… **Gestion d'erreurs robuste** avec retry logic
- âœ… **Rate limiting** et respect des quotas API
- âœ… **Logging complet** pour monitoring et debugging
- âœ… **Idempotence** : rÃ©exÃ©cution sÃ»re du pipeline
- âœ… **Tests de qualitÃ© de donnÃ©es** avec DBT
- âœ… **Orchestration Airflow** avec TaskGroups et monitoring

### Transformations DBT

- âœ… Architecture Bronze â†’ Silver â†’ Gold
- âœ… Tests de donnÃ©es (unicitÃ©, non-null, valeurs acceptÃ©es)
- âœ… Tests personnalisÃ©s (scores valides, dates cohÃ©rentes)
- âœ… Documentation gÃ©nÃ©rÃ©e automatiquement
- âœ… IncrÃ©mental loading support

### Dashboard

- âœ… **5 vues analytiques** :
  - Vue d'ensemble (mÃ©triques clÃ©s)
  - Analyse par compÃ©tition
  - Performance des Ã©quipes
  - Analyse des matchs
  - Deep dive par Ã©quipe
- âœ… Visualisations interactives (Plotly)
- âœ… Cache des donnÃ©es pour performance
- âœ… Responsive design

## ğŸ› ï¸ Stack Technique

| Composant | Technologie | Version |
|-----------|-------------|---------|
| Orchestration | Apache Airflow | 2.7+ |
| Transformation | dbt-core | 1.6+ |
| Base de donnÃ©es | PostgreSQL | 15 |
| Dashboard | Streamlit | 1.28+ |
| Containerization | Docker | 20.10+ |
| Langage | Python | 3.9+ |
| API | Football-Data.org | v4 |

## ğŸ“¦ Installation

### PrÃ©requis

- Python 3.9+
- Docker & Docker Compose
- PostgreSQL 15
- Git
- Compte Football-Data.org (clÃ© API)

### 1. Cloner le Repository

```bash
git clone https://github.com/kabbstat/ELT_FOOTBALL_STAT.git
cd ELT_FOOTBALL_STAT
```

### 2. Configuration de l'Environnement

```bash
# Copier le fichier d'exemple
cp .env.example .env

# Ã‰diter avec vos credentials
nano .env
```

Remplir les variables suivantes :
```bash
DB_HOST=localhost
DB_PORT=5432
DB_NAME=football_stats_db
DB_USER=football_user
DB_PASS=votre_password
FOOTBALL_API_TOKEN=votre_api_token
```

### 3. CrÃ©er la Base de DonnÃ©es PostgreSQL

```bash
# Se connecter Ã  PostgreSQL
psql -U postgres

# CrÃ©er la base de donnÃ©es et l'utilisateur
CREATE DATABASE football_stats_db;
CREATE USER football_user WITH PASSWORD 'votre_password';
GRANT ALL PRIVILEGES ON DATABASE football_stats_db TO football_user;

# CrÃ©er les schÃ©mas
\c football_stats_db
CREATE SCHEMA bronze;
CREATE SCHEMA silver;
CREATE SCHEMA gold;
GRANT ALL ON SCHEMA bronze, silver, gold TO football_user;
```

### 4. Installer les DÃ©pendances Python

```bash
# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirement.txt
```

### 5. DÃ©marrer Airflow avec Docker

```bash
# Construire et dÃ©marrer les conteneurs
docker-compose up -d

# VÃ©rifier les logs
docker-compose logs -f
```

Airflow sera accessible sur `http://localhost:8080`
- Username: `admin`
- Password: `admin`

### 6. Configurer DBT

```bash
# Tester la connexion DBT
cd dbt_football/stat_foot
dbt debug --profiles-dir ~/.dbt

# Installer les dÃ©pendances DBT
dbt deps --profiles-dir ~/.dbt
```

## âš™ï¸ Configuration

### Configuration Airflow

Le DAG est configurÃ© pour s'exÃ©cuter **hebdomadairement** (chaque samedi).

Pour modifier :
```python
# airflow/dags/football_elt_dag_enhanced.py
schedule_interval='@weekly'  # Modifier selon vos besoins
```

### Configuration DBT

Les profils DBT sont dans `~/.dbt/profiles.yml` :

```yaml
stat_foot:
  outputs:
    dev:
      type: postgres
      host: localhost
      port: 5432
      user: football_user
      password: votre_password
      dbname: football_stats_db
      schema: gold
      threads: 4
  target: dev
```

### Configuration API

Limites du free tier Football-Data.org :
- 10 requÃªtes/minute
- 3 compÃ©titions maximum
- DonnÃ©es historiques limitÃ©es

## ğŸš€ Utilisation

### ExÃ©cution Manuelle de l'Extraction

```bash
# Activer l'environnement
source venv/bin/activate

# ExÃ©cuter l'extraction
python extractor/foot_data_enhanced.py

# Charger dans PostgreSQL
python extractor/load_postgres_enhanced.py
```

### ExÃ©cution des Transformations DBT

```bash
cd dbt_football/stat_foot

# Nettoyer les anciens artifacts
dbt clean

# Installer les dÃ©pendances
dbt deps

# ExÃ©cuter les transformations
dbt run --profiles-dir ~/.dbt

# ExÃ©cuter les tests
dbt test --profiles-dir ~/.dbt

# GÃ©nÃ©rer la documentation
dbt docs generate --profiles-dir ~/.dbt
dbt docs serve  # Ouvre sur http://localhost:8080
```

### Lancer le Dashboard

```bash
cd dashboard

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer Streamlit
streamlit run app.py
```

Le dashboard sera accessible sur `http://localhost:8501`

### ExÃ©cution via Airflow

1. AccÃ©der Ã  Airflow : `http://localhost:8080`
2. Activer le DAG `football_elt_pipeline_enhanced`
3. DÃ©clencher manuellement ou attendre l'exÃ©cution planifiÃ©e
4. Monitorer l'exÃ©cution dans l'interface Airflow

## ğŸ“ Structure du Projet

```
football_stat/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ football_elt_dag.py              # DAG original
â”‚   â”‚   â””â”€â”€ football_elt_dag_enhanced.py     # DAG optimisÃ© âœ¨
â”‚   â”œâ”€â”€ logs/                                 # Logs Airflow
â”‚   â””â”€â”€ plugins/
â”‚
â”œâ”€â”€ extractor/
â”‚   â”œâ”€â”€ foot_data.py                         # Extraction original
â”‚   â”œâ”€â”€ foot_data_enhanced.py                # Extraction amÃ©liorÃ©e âœ¨
â”‚   â”œâ”€â”€ load_postgres.py                     # Loading original
â”‚   â””â”€â”€ load_postgres_enhanced.py            # Loading amÃ©liorÃ© âœ¨
â”‚
â”œâ”€â”€ dbt_football/
â”‚   â””â”€â”€ stat_foot/
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ sources.yml                  # Source definitions
â”‚       â”‚   â”œâ”€â”€ silver/
â”‚       â”‚   â”‚   â”œâ”€â”€ stg_matches.sql          # Staging matches âœ¨
â”‚       â”‚   â”‚   â”œâ”€â”€ stg_teams.sql            # Staging teams âœ¨
â”‚       â”‚   â”‚   â””â”€â”€ schema.yaml
â”‚       â”‚   â””â”€â”€ gold/
â”‚       â”‚       â”œâ”€â”€ fact_matches.sql         # Fact table âœ¨
â”‚       â”‚       â”œâ”€â”€ dim_teams.sql            # Dimension table âœ¨
â”‚       â”‚       â”œâ”€â”€ agg_team_performance.sql # Team stats âœ¨
â”‚       â”‚       â”œâ”€â”€ agg_competition_stats.sql # Competition stats âœ¨
â”‚       â”‚       â””â”€â”€ schema.yaml
â”‚       â”œâ”€â”€ tests/
â”‚       â”‚   â”œâ”€â”€ test_valid_scores.sql        # Custom test âœ¨
â”‚       â”‚   â”œâ”€â”€ test_halftime_vs_fulltime.sql # Custom test âœ¨
â”‚       â”‚   â””â”€â”€ test_reasonable_dates.sql    # Custom test âœ¨
â”‚       â””â”€â”€ dbt_project.yml
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py                               # Streamlit dashboard âœ¨
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py                          # Configuration centralisÃ©e âœ¨
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ landing/                             # DonnÃ©es extraites (Parquet)
â”‚   â””â”€â”€ raw/                                 # DonnÃ©es brutes (JSON)
â”‚
â”œâ”€â”€ logs/                                    # Logs applicatifs
â”‚
â”œâ”€â”€ docker-compose.yaml                      # Orchestration Docker
â”œâ”€â”€ Dockerfile                               # Image Docker
â”œâ”€â”€ requirement.txt                          # DÃ©pendances Python
â”œâ”€â”€ .env.example                             # Template configuration âœ¨
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                                # Cette documentation âœ¨
```

## ğŸ§ª QualitÃ© des DonnÃ©es

### Tests DBT ImplÃ©mentÃ©s

#### Tests de Base (sources.yml & schema.yaml)
- UnicitÃ© des IDs
- Non-nullitÃ© des champs critiques
- Valeurs acceptÃ©es pour les statuts

#### Tests PersonnalisÃ©s

1. **test_valid_scores.sql** : VÃ©rifie que les scores sont positifs
2. **test_halftime_vs_fulltime.sql** : Valide que score mi-temps â‰¤ score final
3. **test_reasonable_dates.sql** : VÃ©rifie la cohÃ©rence des dates

### Monitoring et Logging

- **Logs d'extraction** : `logs/extraction.log`
- **Logs de loading** : `logs/loading.log`
- **Logs Airflow** : `airflow/logs/`
- **Logs DBT** : `dbt_football/stat_foot/logs/`

### MÃ©triques de QualitÃ©

Le DAG effectue automatiquement :
- Validation des fichiers extraits
- Comptage des enregistrements
- VÃ©rification de la fraÃ®cheur des donnÃ©es
- Tests de qualitÃ© DBT

## ğŸ“Š Dashboard

### Vues Disponibles

#### 1. Overview (Vue d'ensemble)
- MÃ©triques clÃ©s : Total matches, goals, teams
- Matchs rÃ©cents
- Distribution par compÃ©tition

#### 2. Competition Analysis
- Statistiques par compÃ©tition
- Home advantage analysis
- Tendances des buts
- Tableau dÃ©taillÃ©

#### 3. Team Performance
- Classements par compÃ©tition
- Top scorers
- Meilleures dÃ©fenses
- Tableau complet des standings

#### 4. Match Analysis
- Analyse des matchs Ã  haut score
- Distribution des buts
- Performance domicile vs extÃ©rieur

#### 5. Team Deep Dive
- Analyse dÃ©taillÃ©e par Ã©quipe
- Statistiques de saison
- Forme rÃ©cente
- Performance domicile/extÃ©rieur

### Captures d'Ã©cran

*Ajouter des screenshots du dashboard ici*

## ğŸ¯ Bonnes Pratiques ImplÃ©mentÃ©es

### Data Engineering

âœ… **Architecture mÃ©daillÃ©e (Bronze/Silver/Gold)**
- SÃ©paration claire des responsabilitÃ©s
- TraÃ§abilitÃ© des donnÃ©es
- Facilite le debugging

âœ… **Idempotence**
- RÃ©exÃ©cution sÃ»re du pipeline
- Pas d'effets de bord

âœ… **Error Handling**
- Try/except appropriÃ©s
- Logging dÃ©taillÃ©
- Retry logic avec backoff

âœ… **Configuration Management**
- Variables d'environnement
- Configuration centralisÃ©e
- Secrets management

âœ… **Testing**
- Tests de qualitÃ© de donnÃ©es
- Tests de schÃ©ma
- Tests personnalisÃ©s

âœ… **Monitoring**
- Logs structurÃ©s
- MÃ©triques de pipeline
- Alertes sur Ã©chec

âœ… **Documentation**
- Code documentÃ©
- README complet
- Documentation DBT auto-gÃ©nÃ©rÃ©e

### Code Quality

âœ… **Type Hints** pour Python 3.9+
âœ… **Docstrings** pour toutes les fonctions
âœ… **Logging** au lieu de print()
âœ… **Classes** pour encapsulation
âœ… **Configuration** sÃ©parÃ©e du code
âœ… **Gestion des ressources** (with statements, close())

## ğŸ”§ Troubleshooting

### ProblÃ¨me : API Rate Limit

```python
# Le code gÃ¨re automatiquement avec retry
# VÃ©rifier les logs : logs/extraction.log
```

### ProblÃ¨me : DBT Connection Error

```bash
# Tester la connexion
cd dbt_football/stat_foot
dbt debug --profiles-dir ~/.dbt

# VÃ©rifier profiles.yml
cat ~/.dbt/profiles.yml
```

### ProblÃ¨me : Airflow DAG non visible

```bash
# VÃ©rifier les logs
docker-compose logs airflow-scheduler

# Recharger les DAGs
docker-compose restart airflow-scheduler
```

### ProblÃ¨me : Dashboard ne charge pas les donnÃ©es

```python
# VÃ©rifier la connexion DB
python -c "from dashboard.app import get_database_connection; get_database_connection()"

# VÃ©rifier les donnÃ©es
psql -U football_user -d football_stats_db -c "SELECT COUNT(*) FROM gold.fact_matches;"
```

## ğŸ“ˆ AmÃ©liorations Futures

- [ ] CI/CD avec GitHub Actions
- [ ] Tests unitaires avec pytest
- [ ] Alertes email configurables
- [ ] Support pour plus de compÃ©titions
- [ ] Machine Learning (prÃ©dictions de matchs)
- [ ] API REST pour exposer les donnÃ©es
- [ ] DÃ©ploiement cloud (AWS/GCP/Azure)
- [ ] Monitoring avec Prometheus/Grafana

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“ License

Ce projet est sous licence MIT.

## ğŸ‘¨â€ğŸ’» Auteur

**Kabbstat**
- GitHub: [@kabbstat](https://github.com/kabbstat)
- LinkedIn: [Votre profil LinkedIn]

## ğŸ™ Remerciements

- [Football-Data.org](https://www.football-data.org/) pour l'API
- Apache Airflow community
- dbt Labs
- Streamlit team

---

â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !
